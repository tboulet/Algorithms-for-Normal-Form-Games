algo_name : pdl_forel
algo_config :
  # ForeL parameters
  forel_config:
    q_value_estimation_method : model-based
    dynamics_method : rd
    learning_rate_rd : 0.001
    learning_rate_cum_values : 0.001
    n_monte_carlo_q_evaluation : 20
    regularizer : entropy
  # Iterated FoReL Lyapunov parameters
  n_timesteps_per_iterations : 50000
  n_policies_to_sample: 10000
  population_averaging: arithmetic
  n_last_policies_to_sample : 10000
  sampler_population:

    # Greedy : successively try to maximize the distance to the average of the already sampled population
    method : "greedy"
    # The size of the population sampled.
    size_population : 100
    # The method when using greedy sampling. Either "to_average" or "to_added distance".
    greedy_mode: "to_average"
    # Distance metric for distributions that is used for greedy sampling. Can either be "kl", "l1" or "l2"
    distance: "kl"

    # # Random : random sampling from the population
    # method : "random"
    # size_population : 10
    # distribution: "uniform"  # The sampling distribution, only used if the method is "random". Is either "uniform" or "exponential".
  
  do_mu_update : True
  do_linear_interpolation_mu : False
  alternate_lyap_pc : False
  eta_scheduler_config:
    class_string : core.scheduler:Exponential   # use 'constant' if mu changes through training?
    start_value : 1
    end_value : 0.001
    n_steps : 50000
    
    